{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Převod dat z csv do sqlite databáze\n",
    "Ke spuštění tohoto jupyteru je potřeba\n",
    "1. mít k dispozici mysql server, se kterým budeme pracovat\n",
    "2. upravit přístupové údaje k serveru na dvou místech, kde se používá `create_engine`.\n",
    "\n",
    "Spuštěním buněk z tohoto notebooku dojde k načtení csv dat z `data/netflix` a uložení do mysql databáze podle přihlašovacích údajů v jupyteru.\n",
    "\n",
    "Uložení proběhne ve dvou verzích.\n",
    "\n",
    "1. Tabulky `credits` a `titles`. Tabulka `titles` přitom obsahuje složené sloupce `genres` a `production_countries`.\n",
    "2. Tabulky `titles_clean`, `genres_clean`, `titles_genres_clean`, `production_countries_clean`, `credits_clean` propojené vzdálenými klíči a relacemi 1:N a N:M.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the csv file into a pandas DataFrame\n",
    "credits = pd.read_csv('data/netflix/credits.csv')\n",
    "titles = pd.read_csv('data/netflix/titles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the data into mysql database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded into MySQL database.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Zde nacitame heslo ze souboru heslo.py \n",
    "# Bud tu radku smazte a vyplnte heslo primo, nebo vytvorte soubor heslo.py stejne jako existuje heslo_priklad.py\n",
    "from heslo import db_heslo\n",
    "# Create an engine for MySQL using SQLAlchemy\n",
    "engine = create_engine(f'mysql+pymysql://jenda:{db_heslo}@chrys/jenda')\n",
    "\n",
    "# Save the DataFrame to the MySQL database\n",
    "credits.to_sql('credits', engine, if_exists='replace', index=False)\n",
    "titles.to_sql('titles', engine, if_exists='replace', index=False)\n",
    "\n",
    "# Close the engine connection (optional, as SQLAlchemy handles connections automatically)\n",
    "engine.dispose()\n",
    "\n",
    "print(\"Data successfully loaded into MySQL database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explode genres and production_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "titles_df = titles.copy()\n",
    "\n",
    "# Expand the genres column into a list\n",
    "titles_df['genres'] = titles_df['genres'].apply(eval)\n",
    "titles_df['production_countries'] = titles_df['production_countries'].apply(eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the genres list into separate rows\n",
    "exploded_genres_df = titles_df.explode('genres')[['id', 'genres']]\n",
    "exploded_production_countries_df = titles_df\\\n",
    "    .explode(\"production_countries\")[['id', 'production_countries']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates to create a unique genres DataFrame\n",
    "unique_genres = exploded_genres_df['genres'].drop_duplicates().reset_index(drop=True).reset_index()\n",
    "unique_genres.columns = ['genre_id', 'genre']\n",
    "unique_production_countries = exploded_production_countries_df['production_countries'].drop_duplicates()\\\n",
    "    .reset_index(drop=True).reset_index()\n",
    "unique_production_countries.columns = ['production_country_id', 'production_country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genres = unique_genres.dropna(subset=[\"genre\"])\n",
    "unique_production_countries = unique_production_countries.dropna(subset=['production_country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to create a relationship table between titles and genres\n",
    "title_genre_relationship = exploded_genres_df\\\n",
    "    .merge(unique_genres, left_on='genres', right_on='genre')[['id', 'genre_id']]\n",
    "title_production_country_relationship = exploded_production_countries_df\\\n",
    "    .merge(unique_production_countries, left_on='production_countries', right_on='production_country')[['id', 'production_country_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original genres column from the titles DataFrame\n",
    "titles_df = titles_df.drop(columns=['genres', 'production_countries'])\n",
    "\n",
    "# Reset the index of the titles DataFrame\n",
    "titles_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrames to CSV files (optional)\n",
    "titles_df.to_csv('data/netflix_clean/titles.csv', index=False)\n",
    "unique_genres.to_csv('data/netflix_clean/genres.csv', index=False)\n",
    "title_genre_relationship.to_csv('data/netflix_clean/title_genre_relationship.csv', index=False)\n",
    "unique_production_countries.to_csv('data/netflix_clean/production_countries.csv', index=False)\n",
    "title_production_country_relationship.to_csv(\n",
    "    'data/netflix_clean/title_production_country_relationship.csv', index=False)\n",
    "credits.to_csv('data/netflix_clean/credits.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the clean database to mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded into MySQL database.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Nacist heslo z externiho souboru, nebo import smazat a napsat primo\n",
    "from heslo import db_heslo\n",
    "# Create an engine for MySQL using SQLAlchemy\n",
    "conn = create_engine(f'mysql+pymysql://jenda:{db_heslo}@chrys/jenda')\n",
    "\n",
    "# Save the DataFrame to the SQLite database\n",
    "titles_df.to_sql('titles_clean', conn, if_exists='replace', index=False)\n",
    "unique_genres.to_sql('genres_clean', conn, if_exists='replace', index=False)\n",
    "title_genre_relationship.to_sql('titles_genres_clean', conn, if_exists='replace', index=False)\n",
    "unique_production_countries.to_sql('production_countries_clean', conn, if_exists='replace', index=False)\n",
    "title_production_country_relationship.to_sql(\n",
    "    'titles_production_countries_clean', conn, if_exists='replace', index=False)\n",
    "credits.to_sql('credits_clean', conn, if_exists='replace', index=False)\n",
    "\n",
    "\n",
    "# Close the database connection\n",
    "conn.dispose()\n",
    "\n",
    "print(\"Data successfully loaded into MySQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lipnice-database",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
